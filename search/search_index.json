{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"K-NN atau k-nearestneighbor with python Pengertian KNN adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. KNN dapat digunakan untuk masalah prediksi klasifikasi dan regresi. Namun, ini lebih banyak digunakan dalam masalah klasifikasi di industri. Untuk mengevaluasi teknik apa pun kita biasanya melihat 3 aspek penting: Mudah untuk menginterpretasikan output Waktu perhitungan Kekuatan Prediktif Mari kita ambil beberapa contoh untuk menempatkan KNN dalam skala: Algoritma KNN menunjukkan seluruh parameter pertimbangan. Ini biasanya digunakan untuk interpretasi yang mudah dan waktu perhitungan yang rendah. Kita dapat menerapkan model KNN dengan mengikuti langkah-langkah di bawah ini: Muat data Inisialisasi nilai k Untuk mendapatkan kelas yang diprediksi, beralih dari 1 ke jumlah total poin data pelatihan Hitung jarak antara data tes dan setiap baris data pelatihan. Di sini kita akan menggunakan jarak Euclidean sebagai metrik jarak kita karena ini adalah metode yang paling populer. Metrik lain yang dapat digunakan adalah Chebyshev, cosinus, dll. Urutkan jarak yang dihitung dalam urutan naik berdasarkan nilai jarak Dapatkan baris k atas dari array yang diurutkan Dapatkan kelas paling sering dari baris ini Kembalikan kelas yang diprediksi Implementasi dalam Python import pandas as pd import numpy as np import math import operator #### Langkah pertama # Impor data data = pd . read_csv ( iris.csv ) data . head () # Defining a function which calculates euclidean distance between two data points def euclideanDistance ( data1 , data2 , length ): distance = 0 for x in range ( length ): distance += np . square ( data1 [ x ] - data2 [ x ]) return np . sqrt ( distance ) # Defining our KNN model def knn ( trainingSet , testInstance , k ): distances = {} sort = {} length = testInstance . shape [ 1 ] #### Start of STEP 3 # Calculating euclidean distance between each row of training data and test data for x in range ( len ( trainingSet )): #### Start of STEP 3.1 dist = euclideanDistance ( testInstance , trainingSet . iloc [ x ], length ) distances [ x ] = dist [ 0 ] #### End of STEP 3.1 #### Start of STEP 3.2 # Sorting them on the basis of distance sorted_d = sorted ( distances . items (), key = operator . itemgetter ( 1 )) #### End of STEP 3.2 neighbors = [] #### Start of STEP 3.3 # Extracting top k neighbors for x in range ( k ): neighbors . append ( sorted_d [ x ][ 0 ]) #### End of STEP 3.3 classVotes = {} #### Start of STEP 3.4 # Calculating the most freq class in the neighbors for x in range ( len ( neighbors )): response = trainingSet . iloc [ neighbors [ x ]][ - 1 ] if response in classVotes : classVotes [ response ] += 1 else : classVotes [ response ] = 1 #### End of STEP 3.4 #### Start of STEP 3.5 sortedVotes = sorted ( classVotes . items (), key = operator . itemgetter ( 1 ), reverse = True ) return ( sortedVotes [ 0 ][ 0 ], neighbors ) #### End of STEP 3.5 # buat datatest testSet = [[ 7.2 , 3.6 , 5.1 , 2.5 ]] test = pd . DataFrame ( testSet ) #### Start of STEP 2 # Setting number of neighbors = 1 k = 1 #### End of STEP 2 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # Nearest neighbor print ( neigh ) - [ 141 ] # Setting number of neighbors = 3 k = 3 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # 3 nearest neighbors print ( neigh ) - [ 141 , 139 , 120 ] # Setting number of neighbors = 5 k = 5 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # 5 nearest neighbors print ( neigh ) - [ 141 , 139 , 120 , 145 , 144 ] Membandingkan model kita dengan scikit-learn from sklearn.neighbors import KNeighborsClassifier neigh = KNeighborsClassifier ( n_neighbors = 3 ) neigh . fit ( data . iloc [:, 0 : 4 ], data [ Name ]) # Predicted class print ( neigh . predict ( test )) - [ Iris-virginica ] # 3 nearest neighbors print ( neigh . kneighbors ( test )[ 1 ]) - [[ 141 139 120 ]] Kita dapat melihat bahwa kedua model meramalkan kelas yang sama ('Iris-virginica') dan tetangga terdekat yang sama ([141 139 120]). Oleh karena itu kita dapat menyimpulkan bahwa model kami berjalan seperti yang diharapkan.","title":"KNN"},{"location":"#k-nn-atau-k-nearestneighbor-with-python","text":"","title":"K-NN atau\u00a0k-nearestneighbor\u00a0with python"},{"location":"#pengertian","text":"KNN adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. KNN dapat digunakan untuk masalah prediksi klasifikasi dan regresi. Namun, ini lebih banyak digunakan dalam masalah klasifikasi di industri. Untuk mengevaluasi teknik apa pun kita biasanya melihat 3 aspek penting: Mudah untuk menginterpretasikan output Waktu perhitungan Kekuatan Prediktif Mari kita ambil beberapa contoh untuk menempatkan KNN dalam skala: Algoritma KNN menunjukkan seluruh parameter pertimbangan. Ini biasanya digunakan untuk interpretasi yang mudah dan waktu perhitungan yang rendah. Kita dapat menerapkan model KNN dengan mengikuti langkah-langkah di bawah ini: Muat data Inisialisasi nilai k Untuk mendapatkan kelas yang diprediksi, beralih dari 1 ke jumlah total poin data pelatihan Hitung jarak antara data tes dan setiap baris data pelatihan. Di sini kita akan menggunakan jarak Euclidean sebagai metrik jarak kita karena ini adalah metode yang paling populer. Metrik lain yang dapat digunakan adalah Chebyshev, cosinus, dll. Urutkan jarak yang dihitung dalam urutan naik berdasarkan nilai jarak Dapatkan baris k atas dari array yang diurutkan Dapatkan kelas paling sering dari baris ini Kembalikan kelas yang diprediksi","title":"Pengertian"},{"location":"#implementasi-dalam-python","text":"import pandas as pd import numpy as np import math import operator #### Langkah pertama # Impor data data = pd . read_csv ( iris.csv ) data . head () # Defining a function which calculates euclidean distance between two data points def euclideanDistance ( data1 , data2 , length ): distance = 0 for x in range ( length ): distance += np . square ( data1 [ x ] - data2 [ x ]) return np . sqrt ( distance ) # Defining our KNN model def knn ( trainingSet , testInstance , k ): distances = {} sort = {} length = testInstance . shape [ 1 ] #### Start of STEP 3 # Calculating euclidean distance between each row of training data and test data for x in range ( len ( trainingSet )): #### Start of STEP 3.1 dist = euclideanDistance ( testInstance , trainingSet . iloc [ x ], length ) distances [ x ] = dist [ 0 ] #### End of STEP 3.1 #### Start of STEP 3.2 # Sorting them on the basis of distance sorted_d = sorted ( distances . items (), key = operator . itemgetter ( 1 )) #### End of STEP 3.2 neighbors = [] #### Start of STEP 3.3 # Extracting top k neighbors for x in range ( k ): neighbors . append ( sorted_d [ x ][ 0 ]) #### End of STEP 3.3 classVotes = {} #### Start of STEP 3.4 # Calculating the most freq class in the neighbors for x in range ( len ( neighbors )): response = trainingSet . iloc [ neighbors [ x ]][ - 1 ] if response in classVotes : classVotes [ response ] += 1 else : classVotes [ response ] = 1 #### End of STEP 3.4 #### Start of STEP 3.5 sortedVotes = sorted ( classVotes . items (), key = operator . itemgetter ( 1 ), reverse = True ) return ( sortedVotes [ 0 ][ 0 ], neighbors ) #### End of STEP 3.5 # buat datatest testSet = [[ 7.2 , 3.6 , 5.1 , 2.5 ]] test = pd . DataFrame ( testSet ) #### Start of STEP 2 # Setting number of neighbors = 1 k = 1 #### End of STEP 2 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # Nearest neighbor print ( neigh ) - [ 141 ] # Setting number of neighbors = 3 k = 3 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # 3 nearest neighbors print ( neigh ) - [ 141 , 139 , 120 ] # Setting number of neighbors = 5 k = 5 # Running KNN model result , neigh = knn ( data , test , k ) # Predicted class print ( result ) - Iris - virginica # 5 nearest neighbors print ( neigh ) - [ 141 , 139 , 120 , 145 , 144 ]","title":"Implementasi dalam Python"},{"location":"#membandingkan-model-kita-dengan-scikit-learn","text":"from sklearn.neighbors import KNeighborsClassifier neigh = KNeighborsClassifier ( n_neighbors = 3 ) neigh . fit ( data . iloc [:, 0 : 4 ], data [ Name ]) # Predicted class print ( neigh . predict ( test )) - [ Iris-virginica ] # 3 nearest neighbors print ( neigh . kneighbors ( test )[ 1 ]) - [[ 141 139 120 ]] Kita dapat melihat bahwa kedua model meramalkan kelas yang sama ('Iris-virginica') dan tetangga terdekat yang sama ([141 139 120]). Oleh karena itu kita dapat menyimpulkan bahwa model kami berjalan seperti yang diharapkan.","title":"Membandingkan model kita dengan scikit-learn"}]}